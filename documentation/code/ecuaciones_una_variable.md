# Documentaci√≥n M√≥dulo Ecuaciones de una Variable

## 1- M√©todo de Bisecci√≥n (`bisection(f, a, b, TOL, N0)`)

El **m√©todo de bisecci√≥n** es un m√©todo num√©rico para encontrar la ra√≠z de una funci√≥n continua. Se basa en el **teorema del valor intermedio**, el cual establece que si una funci√≥n `f(x)` es continua en un intervalo `[a, b]` y `f(a)` y `f(b)` tienen signos opuestos, entonces existe al menos un punto c en `[a, b]` tal que `f(c) = 0`.

### Proceso del M√©todo

1. **Verificaci√≥n de la condici√≥n inicial:**  
   Se comprueba que `f(a)` y `f(b)` tengan signos opuestos, es decir, que `f(a) * f(b) < 0`.

2. **Inicializaci√≥n:**  
   Se inicializa el contador en 1 y se eval√∫a `FA = f(a)`.

3. **Iteraci√≥n:**  
   En cada iteraci√≥n se calcula el punto medio y se eval√∫a `FP = f(p)`.  
   Si `FP` es 0 o si la mitad del ancho del intervalo (b-a)/2 es menor que la tolerancia, se retorna `p` junto con el n√∫mero de iteraciones.

4. **Actualizaci√≥n del Intervalo:**  
   Se incrementa i y se decide:
   - Si `FA` y `FP` tienen signos opuestos, la ra√≠z se encuentra en `[ùëé,p]` por lo que se actualiza `b = p`.
   - De lo contrario, la ra√≠z se encuentra en `[p,ùëè]` por lo que se actualiza `a = p` y `FA = FP`.

5. **Fallo:**  
   Si se alcanzan `N0` iteraciones sin convergencia, se lanza un error.

### Parametros de Entrada y Salida
```python
def bisection(f, a, b, TOL=1e-5, N0=100):
    """
    Entradas:
      f        : funci√≥n (callable)
      a, b     : Puntos finales del intervalo en el que se busca la ra√≠z.
      TOL      : Tolerancia para la aproximaci√≥n de la ra√≠z.
      N0       : N√∫mero m√°ximo de iteraciones permitidas.

    Salida:
      Retorna una tupla (p, i) donde:
         - p es la aproximaci√≥n a la ra√≠z.
         - i es el n√∫mero de iteraciones realizadas.
    """
```
### Ejemplo de Uso
Supongamos que queremos encontrar la ra√≠z de la funci√≥n `ùëì(ùë•)=ùë•**2‚àí4` en el intervalo `[0,3]`. Para ello, definimos la funci√≥n y llamamos a bisection_method:

```python
# Definici√≥n de la funci√≥n a analizar
def f(x):
    return x**2 - 4

# Llamada al m√©todo de bisecci√≥n en el intervalo [0, 3]
raiz, iteraciones = bisection_method(f, 0, 3)

print(f"La ra√≠z aproximada es {raiz} encontrada en {iteraciones} iteraciones.")
```

## 2- M√©todo de Iteraci√≥n de Punto Fijo (`fixed_point_iteration(g, p0, TOL, N0)`)

El **m√©todo de iteraci√≥n de punto fijo** es un m√©todo num√©rico para encontrar una soluci√≥n a la ecuaci√≥n `p = g(p)`. La idea es partir de una aproximaci√≥n inicial y generar una sucesi√≥n definida por `p{i+1} = g(pi)`.

Si la funci√≥n `g(p)` es contractiva en la regi√≥n cercana al punto fijo, la sucesi√≥n converge a un valor `p` tal que `p = g(p)`.

### Proceso del M√©todo

**Inicializaci√≥n:**   
  Se inicializa el contador de iteraciones y se inicia un bucle que se ejecuta mientras el n√∫mero de iteraciones no supere `N0`.

- **Proceso:**  
  Se calcula el siguiente valor `p` aplicando la funci√≥n `g` a la aproximaci√≥n actual `p0`.  
  Se verifica si la diferencia entre la nueva aproximaci√≥n y la anterior es menor que la tolerancia. Si es as√≠, se retorna `p` y el n√∫mero de iteraciones y se termina la ejecuci√≥n.

- **Iteraci√≥n:**   
  Se incrementa el contador de iteraciones.
  Se actualiza `p0` con el valor de `p` para la siguiente iteraci√≥n.

- **Fallo:**  
  Si se sale del bucle sin convergencia, se lanza un `ValueError` indicando que el m√©todo fall√≥ tras `N0` iteraciones.

### Parametros de Entrada y Salida

```python
def fixed_point_iteration(g, p0, TOL=1e-5, N0=100):
    """
    Entradas:
      g   : funci√≥n (callable) que define el m√©todo de punto fijo, es decir, g(p).
      p0  : aproximaci√≥n inicial.
      TOL : tolerancia para la convergencia.
      N0  : n√∫mero m√°ximo de iteraciones permitidas.
    
    Salida:
      Retorna una tupla (p, i) donde:
         - p es la aproximaci√≥n a la soluci√≥n.
         - i es el n√∫mero de iteraciones realizadas.
    """
   ```

### Ejemplo de Uso
Definimos la funci√≥n `g(p)` para el problema: `p = cos(p)`

   ```python
   def g(p):
        return math.cos(p)

    # Aproximaci√≥n inicial
    p0 = 1.0

    try:
        solution, iterations = fixed_point_iteration(g, p0, TOL=1e-5, N0=100)
        print(f"La soluci√≥n encontrada es {solution} en {iterations} iteraciones.")
    except ValueError as e:
        print(e)
   ```
## 3- M√©todo de Newton (`newton_method(f, p0, TOL=1e-5, N0=100, factor=1e-8)`)

El M√©todo de Newton es un procedimiento iterativo para encontrar soluciones aproximadas de la ecuaci√≥n `f(x)=0`. Se parte de una aproximaci√≥n inicial y se va mejorando dicha aproximaci√≥n usando la f√≥rmula `p = p0 - f(p0)/f‚Ä≤(p0)`

### Proceso del M√©todo

1. **Inicializaci√≥n:**  
   Se elige una aproximaci√≥n inicial para la ra√≠z de la funci√≥n `f(x)=0`, se establece el contador de iteraciones en 1 y llamamos al metodo privado `_derivative` para calcular la derivada de la funci√≥n.

2. **Iteraci√≥n:**  
   En cada iteraci√≥n se realiza lo siguiente:
   - **C√°lculo de la nueva aproximaci√≥n:**  
     Se calcula:
     `p= p0 ‚àí f(p0)/f‚Ä≤(p0)`, en nuestro caso `p = p0 - f_val / df_val`

     `df_val` se obtiene num√©ricamente mediante el m√©todo de diferencia centrada.
   - **Evaluaci√≥n del cambio:**  
     Se calcula la diferencia para evaluar el progreso de la iteraci√≥n.

   **`threshold`**:   El umbral se define como `factor * (1 + |p0|)`. Esto permite ajustar el umbral en funci√≥n de la escala de la aproximaci√≥n inicial. Si la magnitud de la derivada en `p0` es menor que este umbral, se considera que la derivada es demasiado peque√±a, y por tanto no es seguro aplicar el m√©todo de Newton.
3. **Criterio de Convergencia:**  
   Si la diferencia es menor que la tolerancia predefinida, se considera que la iteraci√≥n ha convergido y se retorna la soluci√≥n aproximada junto con el n√∫mero de iteraciones.

4. **Actualizaci√≥n:**  
   Si la condici√≥n de convergencia no se cumple, se incrementa el contador en 1 y se actualiza `p0` con el valor de `p` para la siguiente iteraci√≥n.

5. **Fallo:**  
   Si la derivada es demasiado peque√±a en `p0` (es decir, menor que el umbral relativo calculado) o si se alcanza el n√∫mero m√°ximo de iteraciones sin convergencia, se lanza un ValueError indicando que el m√©todo de Newton no se puede aplicar o que ha fallado.

### Parametros de Entrada y Salida

```python
def newton_method(f, p0, TOL=1e-5, N0=100, factor=1e-8):
   """
      Entradas:
         f        : funci√≥n (callable) para la cual se busca la ra√≠z, f(x)=0.
         p0       : aproximaci√≥n inicial.
         TOL      : tolerancia para la convergencia.
         N0       : n√∫mero m√°ximo de iteraciones permitidas.
         factor   : factor para calcular el umbral relativo utilizado en la verificaci√≥n de la derivada.
            
      Salida:
         Retorna una tupla (p, i) donde:
            - p es la aproximaci√≥n a la ra√≠z.
            - i es el n√∫mero de iteraciones realizadas.
      """
```

### Ejemplo de Uso
Utilizamos el m√©todo de Newton, usando derivaci√≥n num√©rica, y elegimos una aproximaci√≥n inicial razonable.

   ```python

   def f(x):
      return x**3 - 2

   p0 = 1.5  
   solution, iterations = newton_method(f, p0, TOL=1e-5, N0=100, factor=1e-8)
   print(f"La soluci√≥n encontrada es {solution} en {iterations} iteraciones.")
   ```
## 4- M√©todo de la secante (`secant_method(f, p0, p1, TOL=1e-5, N0=100)`)

El **M√©todo de la Secante** es un m√©todo num√©rico para encontrar una soluci√≥n aproximada a la ecuaci√≥n `f(x)=0` sin requerir el c√°lculo expl√≠cito de la derivada. En lugar de usar la derivada, utiliza dos aproximaciones iniciales y calcula la siguiente aproximaci√≥n mediante la recta secante que une los puntos `(p0, f(p0))` y `(p1, f(p1))`.

### Proceso del M√©todo

1. **Inicializaci√≥n:**  
   Se disponen dos aproximaciones iniciales `p0` y `p1` y se calcula:
   - `q0 = f(p0)`
   - `q1 = f(p1)`
   Se establece el contador de iteraciones en `i = 2`, ya que ya se conocen dos puntos.

2. **Iteraci√≥n:**  
   Mientras que la iteraci√≥n es menor o igual al n√∫mero m√°ximo de iteraciones, se hacen los siguientes pasos:
   - **C√°lculo de la nueva aproximaci√≥n:**  
     Se calcula: `p = p1 - q1 * (p1 - p0) / (q1 - q0)`
   - **Criterio de Convergencia:**  
     Si `|p - p_1| < TOL`, se retorna `p` junto con el n√∫mero de iteraciones.
   - **Actualizaci√≥n:**  
     Se actualizan las variables para la siguiente iteraci√≥n:
     - `p0 <- p1` y `q0 <- q1`
     - `p1 <- p` y `q1 <- f(p)` Se incrementa `i`.

3. **Fallo:**  
   Si se alcanzan `N0` iteraciones sin satisfacer el criterio de convergencia, se lanza un error indicando que el m√©todo no fue exitoso.

### Parametros de Entrada y Salida

```python
def secant_method(f, p0, p1, TOL=1e-5, N0=100):
    """
    Entradas:
      f    : funci√≥n (callable) para la cual se busca la ra√≠z, f(x)=0.
      p0   : primera aproximaci√≥n inicial.
      p1   : segunda aproximaci√≥n inicial.
      TOL  : tolerancia para la convergencia.
      N0   : n√∫mero m√°ximo de iteraciones permitidas.
    
    Salida:
      Retorna una tupla (p, i) donde:
         - p es la aproximaci√≥n a la ra√≠z.
         - i es el n√∫mero de iteraciones realizadas.
```

### Ejemplo de Uso

Considera la ecuaci√≥n `f(x)=x^2-2=0`. La ra√≠z real es `sqrt{2}, approx 1.41421`. Utilizaremos dos aproximaciones iniciales, por ejemplo, `p0=1` y `p1=2`.

```python

def f(x):
    return x**2 - 2

p0 = 1.0
p1 = 2.0

solution, iterations = secant_method(f, p0, p1, TOL=1e-5, N0=100)
print(f"La soluci√≥n encontrada es {solution} en {iterations} iteraciones.")
```
## 5- M√©todo de Posici√≥n Falsa (`false_position(f, p0, p1, TOL=1e-5, N0=100)`)

El **m√©todo de la posici√≥n falsa** es un m√©todo num√©rico para encontrar una soluci√≥n aproximada de la ecuaci√≥n `f(x)=0` cuando la funci√≥n `f` es continua en el intervalo `[p0, p1]` y `f(p0)` y `f(p1)` tienen signos opuestos. La idea es usar una recta secante (la l√≠nea que une los puntos `(p0, f(p0))` y `(p1, f(p1))`) para estimar la ra√≠z.

### Proceso del M√©todo

1. **Inicializaci√≥n:**
   - Se establecen dos aproximaciones iniciales.
   - Se calculan `q0 = f(p0)` y `q1 = f(p1)`.
   - Se fija el contador `i=2`.

2. **Iteraci√≥n:**
   - Se calcula una nueva aproximaci√≥n usando la f√≥rmula de la posici√≥n falsa: `p = p1 - q1 * (p1 - p0) / (q1 - q0)`
   - Si `|p - p_1| < TOL`, se considera que el proceso ha convergido y se retorna `p` junto con el n√∫mero de iteraciones.
   - Se incrementa el contador en 1.
   - Se calcula `q = f(p)`. Luego, se verifica el signo de `q` respecto a `q1`:
     - Si `q * q1 < 0`, se actualiza `p0 = p1` y `q0 = q1`.
   - Se actualiza `p1 = p` y `q1 = q`.
   
3. **Fallo:**
   - Si se alcanza el n√∫mero m√°ximo de iteraciones `N0` sin convergencia, se lanza un error indicando que el m√©todo fall√≥.

### Parametros de Entrada y Salida

```python
def false_position(f, p0, p1, TOL=1e-5, N0=100):
    """
    Entradas:
      f    : funci√≥n (callable) para la cual se busca la ra√≠z, f(x)=0.
      p0   : primera aproximaci√≥n inicial.
      p1   : segunda aproximaci√≥n inicial.
      TOL  : tolerancia para la convergencia.
      N0   : n√∫mero m√°ximo de iteraciones permitidas.
      
    Salida:
      Retorna una tupla (p, i) donde:
         - p es la aproximaci√≥n a la ra√≠z.
         - i es el n√∫mero de iteraciones realizadas.
   """
```

### Diferencia con Metodo de la Secante

Ambos m√©todos utilizan la idea de aproximar la ra√≠z mediante la intersecci√≥n de la l√≠nea secante que une dos puntos en la gr√°fica de `f(x)`, pero difieren en c√≥mo actualizan sus aproximaciones:

- **M√©todo de la Secante**  
  - Utiliza los dos √∫ltimos puntos calculados (sin mantener necesariamente una condici√≥n de bracketing) para generar la nueva aproximaci√≥n mediante: `p = p1 - q1 * (p1 - p0) / (q1 - q0)`.

  - No garantiza que las aproximaciones encuadren una ra√≠z. Esto puede hacer que la convergencia sea r√°pida, pero en algunos casos puede perder la garant√≠a de que la ra√≠z se encuentra entre las aproximaciones.

- **M√©todo de la Falsa Posici√≥n**  
  - Tambi√©n usa la misma f√≥rmula: `p = p1 - q1 * (p1 - p0) / (q1 - q0)`.  
  - Sin embargo, **mantiene siempre un intervalo `[p0, p1]` donde `f(p0)` y `f(p1)` tienen signos opuestos**. Despu√©s de calcular `p`, se decide qu√© extremo actualizar seg√∫n el signo de `f(p)`:
    - Si `f(p)` tiene el mismo signo que `f(p1)`, se actualiza `p0` (y se conserva el bracketing).
    - Si `f(p)` tiene el mismo signo que `f(p0)`, se actualiza `p1`.
  - De esta forma, se garantiza que en cada iteraci√≥n el intervalo sigue conteniendo una ra√≠z.

### Ejemplo de Uso

Consideremos la funci√≥n `f(x)=x^2-3`, cuya ra√≠z real es `sqrt{3} \approx 1.73205`. Utilizaremos las aproximaciones iniciales `p0=1.0` y `p1=2.0`.

```python

def f(x):
    return x**2 - 3

p0 = 1.0
p1 = 2.0

solution, iterations = false_position(f, p0, p1, TOL=1e-5, N0=100)
print(f"La soluci√≥n encontrada es {solution} en {iterations} iteraciones.")
```





## Adicional

### M√©todo privado para derivar `(_derivative(f, TOL=1e-5))`
Metodo privado que retorna una funci√≥n que aproxima la derivada de `f` utilizando la f√≥rmula de diferencia centrada.

**Par√°metros**:
   - **f** : Funci√≥n (callable) de la cual se quiere calcular la derivada.
   - **TOL** : Paso peque√±o para la aproximaci√≥n (por defecto 1e-5).